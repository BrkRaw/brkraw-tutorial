{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# BrkRaw Tutorial 1: Getting Started\n\nThis notebook mirrors the official Getting Started guidance using the\nlatest BrkRaw API and the Git LFS example datasets.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 1. Download example data (Git LFS)\n\nThe example datasets live in `brkraw-dataset` and are stored with Git LFS.\nThis cell clones the repo into `data/brkraw-dataset` and pulls the LFS data.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "from pathlib import Path\nimport subprocess\nimport shutil\n\nDATA_DIR = Path(\"data\")\nDATASET_REPO = DATA_DIR / \"brkraw-dataset\"\n\ndef ensure_git_lfs():\n    if shutil.which(\"git\") is None:\n        raise RuntimeError(\"git is required but not found in PATH.\")\n    result = subprocess.run([\"git\", \"lfs\", \"version\"], capture_output=True, text=True)\n    if result.returncode != 0:\n        raise RuntimeError(\"git-lfs is required. Install it and rerun this cell.\")\n    return result.stdout.strip()\n\nprint(ensure_git_lfs())\nDATA_DIR.mkdir(parents=True, exist_ok=True)\n\nif not DATASET_REPO.exists():\n    subprocess.run([\"git\", \"clone\", \"https://github.com/BrkRaw/brkraw-dataset\", str(DATASET_REPO)], check=True)\n\nsubprocess.run([\"git\", \"-C\", str(DATASET_REPO), \"lfs\", \"pull\"], check=True)\nprint(\"Dataset repo ready:\", DATASET_REPO)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 2. Load a dataset\n\nWe will use the Paravision 6.0.1 example archive.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "from pathlib import Path\nimport brkraw as brk\n\ndataset_zip = DATASET_REPO / \"PV6.0.1\" / \"UNC_PV6.0.1_FLASH_TurboRARE_EPI.zip\"\ndataset_zip.exists()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "loader = brk.load(str(dataset_zip))\nloader.avail\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 3. Inspect study and scan metadata\n\nBrkRaw can return info tables as dictionaries for programmatic access.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "info = loader.info(scope=\"full\", as_dict=True)\ninfo[\"Study\"]\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "sorted(loader.avail.keys())\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 4. Read data arrays and affines\n\nPick the first available scan/reco pair.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "import numpy as np\n\nscan_id = sorted(loader.avail.keys())[0]\nreco_id = sorted(loader.avail[scan_id].avail.keys())[0]\nscan_id, reco_id\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "def first_pack(value):\n    return value[0] if isinstance(value, tuple) else value\n\ndata = first_pack(loader.get_dataobj(scan_id, reco_id=reco_id))\naffine = first_pack(loader.get_affine(scan_id, reco_id=reco_id))\ndata.shape, affine\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 5. Quick visualization\n\nPlot a center slice to verify the data load.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Note: These are 2D (x, y) axis plots of a single slice. We set `origin=\"lower\"` to match the usual neuroimaging display convention so the image axes align with RAS-style orientation in this 2D view."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "import matplotlib.pyplot as plt\n\nslice_idx = data.shape[2] // 2\nplt.imshow(np.rot90(data[:, :, slice_idx]), cmap=\"gray\", origin=\"lower\")\nplt.title(f\"Scan {scan_id}, Reco {reco_id}, slice {slice_idx}\")\nplt.axis(\"off\")\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 6. Convert to NIfTI\n\nConvert the selected scan to NIfTI and write it to `outputs/`.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "from pathlib import Path\n\nout_dir = Path(\"outputs\")\nout_dir.mkdir(exist_ok=True)\n\nnifti = loader.convert(scan_id, reco_id=reco_id, format=\"nifti\")\nif isinstance(nifti, tuple):\n    for idx, img in enumerate(nifti, start=1):\n        img.to_filename(out_dir / f\"scan{scan_id}_reco{reco_id}_slpack{idx}.nii.gz\")\nelse:\n    nifti.to_filename(out_dir / f\"scan{scan_id}_reco{reco_id}.nii.gz\")\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 7. Metadata and parameter search\n\nPull metadata and search for a parameter key.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "meta = loader.get_metadata(scan_id, reco_id=reco_id)\nif meta:\n    list(meta.keys())[:10]\nelse:\n    meta\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "loader.search_params(\"PVM_RepetitionTime\", scan_id=scan_id)\n",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}